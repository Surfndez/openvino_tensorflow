{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9dee09d",
   "metadata": {},
   "source": [
    "# Basic Classification and Object Detection on OpenVINO™ Integration with TensorFlow\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is a sample to showcase classification and object detection in images. For classification, InceptionV3 Model trained on ImageNet dataset is used and for object detection, Yolo V3 trained on COCO dateset used. This sample also showcases the performance and inference results using stock TensorFlow (Intel® CPUs) and OpenVINO™ Integration with TensorFlow (Intel® CPUs and Accelerators).\n",
    "\n",
    "Accelerators refer to:\n",
    "* Intel® integrated GPUs\n",
    "* Intel® Neural Compute Stick with Movidius™ Vision Processing Units - referred as NCS2\n",
    "* Intel® Vision Accelerator Design with 8 Intel Movidius™ MyriadX VPUs - referred as VAD-M or HDDL\n",
    "\n",
    "First, we implement a standard TensorFlow classification application. The application loads the frozen TensorFlow graph, reads the input image and executes the inference on stock TensorFlow. Then, we activate OpenVINO™ integration with TensorFlow by adding two lines of code and re-run the inference. This sample will be running the inference on Intel® Core CPU only. To try other supported devices like Intel® HD Graphics GPU, Intel® Neural Compute Stick 2, and Intel® VAD-M, please use the more advanced samples.\n",
    "  \n",
    "## Install Prerequisites\n",
    "\n",
    "Install TensorFlow, OpenVINO integration with TensorFlow, and additional prerequisities required for the demo. If any other version of TensorFlow is pre-installed on your system, you need to uninstall it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45915dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow==2.4.1\n",
    "!pip3 install openvino-tensorflow\n",
    "\n",
    "!pip3 install numpy matplotlib opencv-python pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3706a",
   "metadata": {},
   "source": [
    "## Download Models, Images, and Labels\n",
    "\n",
    "Download the models, images and labels required for the demo.\n",
    "\n",
    "Note: You need to have python3-venv installed on your system before running the cell below. For Ubuntu 18.04, you can install it by running \"apt-get install python3-venv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7364591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!curl -L \"https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\" | tar -C data -xz\n",
    "!curl -L \"https://raw.githubusercontent.com/openvinotoolkit/openvino_tensorflow/notebook_demo_branch/examples/data/grace_hopper.jpg\" -o \"data/grace_hopper.jpg\"\n",
    "\n",
    "!wget https://raw.githubusercontent.com/openvinotoolkit/openvino_tensorflow/notebook_demo_branch/examples/convert_yolov3_160.sh\n",
    "!wget https://raw.githubusercontent.com/openvinotoolkit/openvino_tensorflow/notebook_demo_branch/examples/convert_yolov3.patch\n",
    "!source convert_yolov3_160.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701fc48c",
   "metadata": {},
   "source": [
    "## Classification Sample\n",
    "\n",
    "### Import Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00463db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee9829",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    assert os.path.exists(model_file), \"Could not find model path\"\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def read_tensor_from_image_file(image_file,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    assert os.path.exists(image_file), \"Could not find image file path\"\n",
    "    image = cv2.imread(image_file)\n",
    "    resized = cv2.resize(image, (input_height, input_width))\n",
    "    img = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "    resized_image = img.astype(np.float32)\n",
    "    normalized_image = (resized_image - input_mean) / input_std\n",
    "    result = np.expand_dims(normalized_image, 0)\n",
    "    return result, image\n",
    "\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    assert os.path.exists(label_file), \"Could not find label file path\"\n",
    "    proto_as_ascii_lines = tf.io.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "def print_classification_predictions(label_file, results):\n",
    "    results = np.squeeze(results)\n",
    "    with open(label_file) as file:\n",
    "        labels = file.readlines()\n",
    "    sorted_idx = np.argsort(results)\n",
    "    print(\"Predictions:\")\n",
    "    for i in range(3):\n",
    "        cls_index = sorted_idx[-(i+1)]\n",
    "        label = labels[cls_index].strip()\n",
    "        print(\"\\t\",label,\" (\", \"{:.8f}\".format(results[cls_index]),\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4679a",
   "metadata": {},
   "source": [
    "### Set Variables for Classification Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a361729",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/grace_hopper.jpg\"\n",
    "model_file = \"data/inception_v3_2016_08_28_frozen.pb\"\n",
    "label_file = \"data/imagenet_slim_labels.txt\"\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "input_layer = \"input\"\n",
    "output_layer = \"InceptionV3/Predictions/Reshape_1\"\n",
    "backend_name = \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d5c07",
   "metadata": {},
   "source": [
    "### Load the Model and the Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d266ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(model_file)\n",
    "\n",
    "t, img = read_tensor_from_image_file(\n",
    "         file_name,\n",
    "         input_height=input_height,\n",
    "         input_width=input_width,\n",
    "         input_mean=input_mean,\n",
    "         input_std=input_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289712b",
   "metadata": {},
   "source": [
    "### Import OpenVINO-TensorFlow Module and Set Backend\n",
    "\n",
    "**DO NOT RUN** the cell below yet.\n",
    "1. Skip this section and move on to the next section to run inference on stock TensorFlow. Note the inference latency.\n",
    "2. Then, uncomment and run the cell when instructed below to activate OpenVINO integration with TensorFlow and run the inference again. Compare the inference latency with the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenVINO integration with TensorFlow and set the backend device\n",
    "#import openvino_tensorflow as ovtf\n",
    "#ovtf.set_backend('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad203f",
   "metadata": {},
   "source": [
    "### Run the Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    # Warmup\n",
    "    results = sess.run(output_operation.outputs[0],\n",
    "                       {input_operation.outputs[0]: t})\n",
    "\n",
    "    # Run\n",
    "    start = time.time()\n",
    "    results = sess.run(output_operation.outputs[0],\n",
    "                       {input_operation.outputs[0]: t})\n",
    "    elapsed = time.time() - start\n",
    "    print('OVTF Inference time in ms: %.2f' % (elapsed * 1000))\n",
    "    \n",
    "    print_classification_predictions(label_file, results)\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63eeef9",
   "metadata": {},
   "source": [
    "### Enable/Disable OpenVINO integration with TensorFlow\n",
    "\n",
    "Once you import OpenVINO-TensorFlow module, OpenVINO integration with TensorFlow will be enabled by default. If you need to manually enable/disable OpenVINO integration with TensorFlow, please use the API calls below and execute the inference again.\n",
    "\n",
    "**To disable** OpenVINO ingtegration with TensorFlow, execute the cell below before running the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8305b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovtf.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff45990",
   "metadata": {},
   "source": [
    "**To enable** OpenVINO ingtegration with TensorFlow, execute the cell below before running the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovtf.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76019c2e",
   "metadata": {},
   "source": [
    "## Object Detection Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5caabb",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14624941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(predictions_with_boxes,\n",
    "                        confidence_threshold,\n",
    "                        iou_threshold=0.4):\n",
    "    conf_mask = np.expand_dims(\n",
    "        (predictions_with_boxes[:, :, 4] > confidence_threshold), -1)\n",
    "    predictions = predictions_with_boxes * conf_mask\n",
    "\n",
    "    result = {}\n",
    "    for i, image_pred in enumerate(predictions):\n",
    "        shape = image_pred.shape\n",
    "        non_zero_idxs = np.nonzero(image_pred)\n",
    "        image_pred = image_pred[non_zero_idxs]\n",
    "        image_pred = image_pred.reshape(-1, shape[-1])\n",
    "\n",
    "        bbox_attrs = image_pred[:, :5]\n",
    "        classes = image_pred[:, 5:]\n",
    "        classes = np.argmax(classes, axis=-1)\n",
    "\n",
    "        unique_classes = list(set(classes.reshape(-1)))\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls_mask = classes == cls\n",
    "            cls_boxes = bbox_attrs[np.nonzero(cls_mask)]\n",
    "            cls_boxes = cls_boxes[cls_boxes[:, -1].argsort()[::-1]]\n",
    "            cls_scores = cls_boxes[:, -1]\n",
    "            cls_boxes = cls_boxes[:, :-1]\n",
    "\n",
    "            while len(cls_boxes) > 0:\n",
    "                box = cls_boxes[0]\n",
    "                score = cls_scores[0]\n",
    "                if cls not in result:\n",
    "                    result[cls] = []\n",
    "                result[cls].append((box, score))\n",
    "                cls_boxes = cls_boxes[1:]\n",
    "                # iou threshold check for overlapping boxes\n",
    "                ious = np.array([iou(box, x) for x in cls_boxes])\n",
    "                iou_mask = ious < iou_threshold\n",
    "                cls_boxes = cls_boxes[np.nonzero(iou_mask)]\n",
    "                cls_scores = cls_scores[np.nonzero(iou_mask)]\n",
    "\n",
    "    return result\n",
    "\n",
    "def convert_to_original_size(box, size, original_size, is_letter_box_image):\n",
    "    if is_letter_box_image:\n",
    "        box = box.reshape(2, 2)\n",
    "        box[0, :] = letter_box_pos_to_original_pos(box[0, :], size,\n",
    "                                                   original_size)\n",
    "        box[1, :] = letter_box_pos_to_original_pos(box[1, :], size,\n",
    "                                                   original_size)\n",
    "    else:\n",
    "        ratio = original_size / size\n",
    "        box = box.reshape(2, 2) * ratio\n",
    "    return list(box.reshape(-1))\n",
    "\n",
    "def draw_boxes(boxes, img, cls_names, detection_size, is_letter_box_image):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for cls, bboxs in boxes.items():\n",
    "        #color = (256, 256, 256)\n",
    "        color = (256, 0, 0)\n",
    "        for box, score in bboxs:\n",
    "            box = convert_to_original_size(box, np.array(detection_size),\n",
    "                                           np.array(img.size),\n",
    "                                           is_letter_box_image)\n",
    "            draw.rectangle(box, outline=color, width=4)\n",
    "            if os.path.isfile(\"/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf\"):\n",
    "                font = ImageFont.truetype(\"DejaVuSerif-Bold.ttf\", int(img.size[0]/16))\n",
    "            else:\n",
    "                font = ImageFont.load_default()\n",
    "            text_pos = box[:2]\n",
    "            text_pos[0] += int(img.size[0]/32)\n",
    "            text_pos[1] += int(img.size[1]/32)\n",
    "            draw.text(\n",
    "                text_pos,\n",
    "                '{} {:.2f}%'.format(cls_names[cls], score * 100),\n",
    "                fill=color, font=font)\n",
    "\n",
    "    # converting PIL image back to OpenCV format\n",
    "    im_np = np.asarray(img)\n",
    "    return im_np\n",
    "\n",
    "def load_coco_names(file_name):\n",
    "    names = {}\n",
    "    assert os.path.exists(file_name), \"path doesn't exist {0}\".format(file_name)\n",
    "    with open(file_name) as f:\n",
    "        for coco_id, name in enumerate(f):\n",
    "            names[coco_id] = name\n",
    "    return names\n",
    "\n",
    "def letter_box_pos_to_original_pos(letter_pos, current_size,\n",
    "                                   ori_image_size) -> np.ndarray:\n",
    "    letter_pos = np.asarray(letter_pos, dtype=np.float)\n",
    "    current_size = np.asarray(current_size, dtype=np.float)\n",
    "    ori_image_size = np.asarray(ori_image_size, dtype=np.float)\n",
    "    final_ratio = min(current_size[0] / ori_image_size[0],\n",
    "                      current_size[1] / ori_image_size[1])\n",
    "    pad = 0.5 * (current_size - final_ratio * ori_image_size)\n",
    "    pad = pad.astype(np.int32)\n",
    "    to_return_pos = (letter_pos - pad) / final_ratio\n",
    "    return to_return_pos\n",
    "\n",
    "def letter_box_image(image_path, input_height, input_width,\n",
    "                     fill_value) -> np.ndarray:\n",
    "    image = Image.open(image_path)\n",
    "    height_ratio = float(input_height) / image.size[1]\n",
    "    width_ratio = float(input_width) / image.size[0]\n",
    "    fit_ratio = min(width_ratio, height_ratio)\n",
    "    fit_height = int(image.size[1] * fit_ratio)\n",
    "    fit_width = int(image.size[0] * fit_ratio)\n",
    "    fit_image = np.asarray(\n",
    "        image.resize((fit_width, fit_height), resample=Image.BILINEAR))\n",
    "\n",
    "    fill_value = np.full(fit_image.shape[2], fill_value, fit_image.dtype)\n",
    "    to_return = np.tile(fill_value, (input_height, input_width, 1))\n",
    "    pad_top = int(0.5 * (input_height - fit_height))\n",
    "    pad_left = int(0.5 * (input_width - fit_width))\n",
    "    to_return[pad_top:pad_top + fit_height, pad_left:pad_left +\n",
    "              fit_width] = fit_image\n",
    "    return to_return, image\n",
    "\n",
    "def iou(box1, box2):\n",
    "    b1_x0, b1_y0, b1_x1, b1_y1 = box1\n",
    "    b2_x0, b2_y0, b2_x1, b2_y1 = box2\n",
    "\n",
    "    int_x0 = max(b1_x0, b2_x0)\n",
    "    int_y0 = max(b1_y0, b2_y0)\n",
    "    int_x1 = min(b1_x1, b2_x1)\n",
    "    int_y1 = min(b1_y1, b2_y1)\n",
    "\n",
    "    int_area = (int_x1 - int_x0) * (int_y1 - int_y0)\n",
    "\n",
    "    b1_area = (b1_x1 - b1_x0) * (b1_y1 - b1_y0)\n",
    "    b2_area = (b2_x1 - b2_x0) * (b2_y1 - b2_y0)\n",
    "\n",
    "    iou = int_area / (b1_area + b2_area - int_area + 1e-05)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361d4ee",
   "metadata": {},
   "source": [
    "### Set Variables for Object Detection Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f04380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"data/yolo_v3_160.pb\"\n",
    "input_layer = \"inputs\"\n",
    "output_layer = \"output_boxes\"\n",
    "label_file = \"data/coco.names\"\n",
    "input_height = 160\n",
    "input_width = 160\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "conf_threshold = 0.6\n",
    "iou_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c708a5",
   "metadata": {},
   "source": [
    "### Load the Model, Image, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f322bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(model_file)\n",
    "\n",
    "img_resized, img = letter_box_image(file_name, input_height, input_width, 128)\n",
    "img_resized = img_resized.astype(np.float32)\n",
    "\n",
    "labels = load_coco_names(label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf56d99",
   "metadata": {},
   "source": [
    "### Enable/Disable OpenVINO integration with TensorFlow\n",
    "\n",
    "Since we already imported OpenVINO-TensorFlow module in the classification sample above, it is already activated. To enable or disable it, you need to use the API calls below accordingly before running the inference.\n",
    "\n",
    "**To disable** OpenVINO ingtegration with TensorFlow, execute the cell below before running the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f04dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovtf.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea354e",
   "metadata": {},
   "source": [
    "**To enable** OpenVINO ingtegration with TensorFlow, execute the cell below before running the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3075b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovtf.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e72cc7",
   "metadata": {},
   "source": [
    "### Run the Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc21f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    # Warmup\n",
    "    detected_boxes = sess.run(output_operation.outputs[0],\n",
    "                              {input_operation.outputs[0]: [img_resized]})\n",
    "    # Run\n",
    "    import time\n",
    "    start = time.time()\n",
    "    detected_boxes = sess.run(output_operation.outputs[0],\n",
    "                              {input_operation.outputs[0]: [img_resized]})\n",
    "    elapsed = time.time() - start\n",
    "    print('Inference time in ms: %f' % (elapsed * 1000))\n",
    "    \n",
    "    # apply non max suppresion, draw boxes and show updated image\n",
    "    filtered_boxes = non_max_suppression(detected_boxes, conf_threshold,\n",
    "                                         iou_threshold)\n",
    "    result_img = draw_boxes(filtered_boxes, img, labels, (input_width, input_height), True)\n",
    "    \n",
    "    plt.imshow(result_img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tensorflow_OpenVINO 2021.4)",
   "language": "python",
   "name": "c003-python_3_ovtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
